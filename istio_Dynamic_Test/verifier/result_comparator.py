#!/usr/bin/env python3
"""
ç»“æœå¯¹æ¯”å™¨

ä¸»è¦åŠŸèƒ½ï¼š
1. æ¯”è¾ƒå®é™…è§‚æµ‹è¡Œä¸ºä¸æœŸæœ›è¡Œä¸º
2. ç”Ÿæˆè¯¦ç»†çš„éªŒè¯ç»“æœ
3. æä¾›å¤šç»´åº¦çš„ä¸€è‡´æ€§æ£€æŸ¥
"""

import math
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from enum import Enum

# å…¨å±€å¯è°ƒå˜é‡ï¼šæµé‡åˆ†å¸ƒéªŒè¯çš„å®¹é”™è¦†ç›–ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰ã€‚
# å°†å…¶è®¾ä¸º None è¡¨ç¤ºä½¿ç”¨ç”¨ä¾‹çŸ©é˜µä¸­çš„ margin_of_errorï¼ˆæˆ–åŠ¨æ€å®¹é”™ï¼‰ã€‚
# ä¾‹å¦‚ï¼šå°†å…¶è®¾ç½®ä¸º 0.08 å¯æ”¾å®½ä¸º Â±8%ã€‚
TRAFFIC_SPLIT_MARGIN_OVERRIDE: Optional[float] = None

from .log_parser import LogEntry, EnvoyLogParser
from .behavior_model import ExpectedBehavior, TestType, PolicyType

class VerificationStatus(Enum):
    """éªŒè¯çŠ¶æ€æšä¸¾"""
    PASSED = "passed"
    FAILED = "failed"
    WARNING = "warning"
    SKIPPED = "skipped"

@dataclass
class VerificationResult:
    """å•é¡¹éªŒè¯ç»“æœ"""
    test_name: str
    case_id: str
    status: VerificationStatus
    expected_value: Any
    actual_value: Any
    deviation: Optional[float] = None
    message: str = ""
    details: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def is_passed(self) -> bool:
        return self.status == VerificationStatus.PASSED
    
    @property
    def is_failed(self) -> bool:
        return self.status == VerificationStatus.FAILED

@dataclass
class ComprehensiveResult:
    """ç»¼åˆéªŒè¯ç»“æœ"""
    case_id: str
    test_description: str
    overall_status: VerificationStatus
    individual_results: List[VerificationResult]
    summary: str
    metrics: Dict[str, Any]
    
    @property
    def passed_count(self) -> int:
        return sum(1 for r in self.individual_results if r.is_passed)
    
    @property
    def failed_count(self) -> int:
        return sum(1 for r in self.individual_results if r.is_failed)
    
    @property
    def success_rate(self) -> float:
        if not self.individual_results:
            return 0.0
        return self.passed_count / len(self.individual_results)

class ResultComparator:
    """ç»“æœå¯¹æ¯”å™¨"""
    
    def __init__(self, log_parser: Optional[EnvoyLogParser] = None):
        """
        åˆå§‹åŒ–å¯¹æ¯”å™¨
        
        Args:
            log_parser: æ—¥å¿—è§£æå™¨å®ä¾‹
        """
        self.log_parser = log_parser or EnvoyLogParser()
    
    def _verify_http_status(self, case_id: str, expected_behavior: ExpectedBehavior,
                          http_results: Dict) -> VerificationResult:
        """
        éªŒè¯HTTPçŠ¶æ€ç  (ä¸»è¦éªŒè¯æŒ‡æ ‡)
        
        Args:
            case_id: æµ‹è¯•ç”¨ä¾‹ID
            expected_behavior: æœŸæœ›è¡Œä¸º
            http_results: HTTPæµ‹è¯•ç»“æœ
            
        Returns:
            VerificationResult: éªŒè¯ç»“æœ
        """
        status_codes = http_results.get('status_codes', {})
        total_requests = http_results.get('total_requests', 0)
        success_rate = http_results.get('success_rate', 0.0)
        avg_response_time = http_results.get('avg_response_time', 0.0)
        
        # åˆ¤æ–­æˆåŠŸæ ‡å‡†
        expected_success_rate = getattr(expected_behavior, 'expected_success_rate', None) or 100.0
        expected_max_response_time = getattr(expected_behavior, 'expected_max_response_time', None) or 5.0
        
        # ä¸»è¦åˆ¤æ–­ï¼šæˆåŠŸç‡å’Œå“åº”æ—¶é—´
        success_ok = success_rate >= expected_success_rate
        time_ok = avg_response_time <= expected_max_response_time
        
        if success_ok and time_ok:
            status = VerificationStatus.PASSED
            message = f"HTTPéªŒè¯é€šè¿‡: æˆåŠŸç‡{success_rate:.1f}% >= {expected_success_rate}%, å¹³å‡å“åº”æ—¶é—´{avg_response_time:.3f}s <= {expected_max_response_time}s"
        else:
            status = VerificationStatus.FAILED
            issues = []
            if not success_ok:
                issues.append(f"æˆåŠŸç‡ä¸è¶³: {success_rate:.1f}% < {expected_success_rate}%")
            if not time_ok:
                issues.append(f"å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.3f}s > {expected_max_response_time}s")
            message = f"HTTPéªŒè¯å¤±è´¥: {'; '.join(issues)}"
        
        # çŠ¶æ€ç åˆ†å¸ƒè¯¦æƒ…
        status_details = []
        for code, count in status_codes.items():
            percentage = (count / total_requests * 100) if total_requests > 0 else 0
            status_details.append(f"{code}: {count}ä¸ªè¯·æ±‚ ({percentage:.1f}%)")
        
        return VerificationResult(
            test_name="HTTPçŠ¶æ€ç éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=f"æˆåŠŸç‡>={expected_success_rate}%, å“åº”æ—¶é—´<={expected_max_response_time}s",
            actual_value=f"æˆåŠŸç‡{success_rate:.1f}%, å“åº”æ—¶é—´{avg_response_time:.3f}s",
            message=message,
            details={
                "status_codes": status_codes,
                "status_details": status_details,
                "total_requests": total_requests,
                "success_rate": success_rate,
                "avg_response_time": avg_response_time
            }
        )
    
    def compare_single_result(self, case_id: str, expected_behavior: ExpectedBehavior,
                            parsed_logs: Dict[str, List[LogEntry]], 
                            http_results: Dict = None) -> ComprehensiveResult:
        """
        æ¯”è¾ƒå•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„ç»“æœ - å¤šç»´åº¦éªŒè¯
        
        Args:
            case_id: æµ‹è¯•ç”¨ä¾‹ ID
            expected_behavior: æœŸæœ›è¡Œä¸º
            parsed_logs: è§£æåçš„æ—¥å¿—æ•°æ®
            http_results: HTTPæµ‹è¯•ç»“æœ (åŒ…å«çŠ¶æ€ç ã€å“åº”æ—¶é—´ç­‰)
            
        Returns:
            ç»¼åˆéªŒè¯ç»“æœ
        """
        individual_results = []
        
        # 1. HTTPçŠ¶æ€ç éªŒè¯ (ä¸»è¦æŒ‡æ ‡ - æœ€å¯é )
        if http_results:
            http_result = self._verify_http_status(case_id, expected_behavior, http_results)
            individual_results.append(http_result)
        
        # 2. åŸºæœ¬ç»Ÿè®¡éªŒè¯ (æ—¥å¿—ç»´åº¦ - å¯èƒ½æœ‰å»¶è¿Ÿ)
        total_requests = sum(len(entries) for entries in parsed_logs.values())
        basic_result = self._verify_basic_metrics(
            case_id, expected_behavior, total_requests
        )
        individual_results.append(basic_result)
        
        # 2. æ ¹æ®æµ‹è¯•ç±»å‹å’Œé…ç½®è¿›è¡Œå…·ä½“éªŒè¯
        
        # è·¯ç”±éªŒè¯
        if (expected_behavior.test_type == TestType.SINGLE_REQUEST or 
            expected_behavior.expected_destination):
            route_result = self._verify_routing(case_id, expected_behavior, parsed_logs)
            individual_results.append(route_result)
        
        # æµé‡åˆ†å¸ƒéªŒè¯
        if (expected_behavior.policy_type == PolicyType.TRAFFIC_SPLIT or
            expected_behavior.expected_distribution):
            dist_result = self._verify_traffic_distribution(
                case_id, expected_behavior, parsed_logs
            )
            individual_results.append(dist_result)
        
        # ç†”æ–­å™¨éªŒè¯
        if (expected_behavior.policy_type == PolicyType.CIRCUIT_BREAKER or
            expected_behavior.expected_trip_threshold or
            expected_behavior.expected_circuit_breaker_threshold):
            cb_result = self._verify_circuit_breaker(
                case_id, expected_behavior, parsed_logs
            )
            individual_results.append(cb_result)
        
        # é‡è¯•éªŒè¯
        if (expected_behavior.policy_type == PolicyType.RETRY or
            expected_behavior.expected_retry_attempts or
            expected_behavior.expected_max_retries):
            retry_result = self._verify_retry(
                case_id, expected_behavior, parsed_logs
            )
            individual_results.append(retry_result)
        
        # æ•…éšœæ³¨å…¥éªŒè¯
        if (expected_behavior.policy_type == PolicyType.FAULT_INJECTION or
            expected_behavior.expected_fault_code or
            expected_behavior.expected_fault_rate):
            fault_result = self._verify_fault_injection(
                case_id, expected_behavior, parsed_logs
            )
            individual_results.append(fault_result)
        
        # 5. æ€§èƒ½æŒ‡æ ‡éªŒè¯
        performance_result = self._verify_performance_metrics(
            case_id, expected_behavior, parsed_logs
        )
        individual_results.append(performance_result)
        
        # 6. è®¡ç®—ç»¼åˆçŠ¶æ€ï¼ˆæŒ‰ç­–ç•¥ç±»å‹å®šåˆ¶å¿…éœ€ç»´åº¦ï¼‰
        overall_status = self._calculate_overall_status_policy_aware(expected_behavior, individual_results)
        
        # 7. ç”ŸæˆæŒ‡æ ‡æ‘˜è¦
        metrics = self._generate_metrics_summary(parsed_logs)
        
        # 8. ç”Ÿæˆæ–‡å­—æ‘˜è¦
        summary = self._generate_summary(expected_behavior, individual_results, metrics)
        
        return ComprehensiveResult(
            case_id=case_id,
            test_description=expected_behavior.description,
            overall_status=overall_status,
            individual_results=individual_results,
            summary=summary,
            metrics=metrics
        )
    
    def _verify_basic_metrics(self, case_id: str, expected_behavior: ExpectedBehavior,
                            total_requests: int) -> VerificationResult:
        """éªŒè¯åŸºæœ¬æŒ‡æ ‡"""
        expected_min = expected_behavior.minimum_requests
        
        if total_requests >= expected_min:
            status = VerificationStatus.PASSED
            message = f"è¯·æ±‚æ•°é‡å……è¶³: {total_requests} >= {expected_min}"
        else:
            status = VerificationStatus.FAILED
            message = f"è¯·æ±‚æ•°é‡ä¸è¶³: {total_requests} < {expected_min}"
        
        return VerificationResult(
            test_name="åŸºæœ¬æŒ‡æ ‡éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=expected_min,
            actual_value=total_requests,
            message=message
        )
    
    def _verify_routing(self, case_id: str, expected_behavior: ExpectedBehavior,
                       parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯è·¯ç”±è¡Œä¸º"""
        expected_dest = expected_behavior.expected_destination
        
        if not expected_dest:
            return VerificationResult(
                test_name="è·¯ç”±éªŒè¯",
                case_id=case_id,
                status=VerificationStatus.SKIPPED,
                expected_value=None,
                actual_value=None,
                message="æœªé…ç½®æœŸæœ›ç›®æ ‡ç‰ˆæœ¬"
            )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯·æ±‚å‘½ä¸­æœŸæœ›çš„ç‰ˆæœ¬
        target_pods = [pod for pod in parsed_logs.keys() 
                      if f"-{expected_dest}-" in pod]
        
        if target_pods:
            total_target_requests = sum(len(parsed_logs[pod]) for pod in target_pods)
            total_requests = sum(len(entries) for entries in parsed_logs.values())
            
            if total_target_requests > 0:
                status = VerificationStatus.PASSED
                message = f"æˆåŠŸè·¯ç”±åˆ°ç›®æ ‡ç‰ˆæœ¬ {expected_dest}"
                details = {
                    'target_pods': target_pods,
                    'target_requests': total_target_requests,
                    'total_requests': total_requests,
                    'routing_ratio': total_target_requests / total_requests if total_requests > 0 else 0
                }
            else:
                status = VerificationStatus.FAILED
                message = f"æœªæ‰¾åˆ°è·¯ç”±åˆ°ç‰ˆæœ¬ {expected_dest} çš„è¯·æ±‚"
                details = {'target_pods': target_pods}
        else:
            status = VerificationStatus.FAILED
            message = f"æœªæ‰¾åˆ°ç‰ˆæœ¬ {expected_dest} çš„ pod"
            details = {'available_pods': list(parsed_logs.keys())}
        
        return VerificationResult(
            test_name="è·¯ç”±éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=expected_dest,
            actual_value=target_pods,
            message=message,
            details=details
        )
    
    def _verify_traffic_distribution(self, case_id: str, expected_behavior: ExpectedBehavior,
                                   parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯æµé‡åˆ†å¸ƒ"""
        expected_dist = expected_behavior.expected_distribution
        margin_of_error = expected_behavior.margin_of_error
        # ä»£ç çº§å¯è°ƒè¦†ç›–ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if TRAFFIC_SPLIT_MARGIN_OVERRIDE is not None:
            margin_of_error = float(TRAFFIC_SPLIT_MARGIN_OVERRIDE)
        
        if not expected_dist:
            return VerificationResult(
                test_name="æµé‡åˆ†å¸ƒéªŒè¯",
                case_id=case_id,
                status=VerificationStatus.SKIPPED,
                expected_value=None,
                actual_value=None,
                message="æœªé…ç½®æœŸæœ›åˆ†å¸ƒ"
            )
        
        # åˆ†æå®é™…åˆ†å¸ƒ
        service_name = self._extract_service_name_from_logs(parsed_logs)
        distribution_result = self.log_parser.analyze_distribution(parsed_logs, service_name)
        total_requests = distribution_result.get('total_requests', 0)
        
        # åŠ¨æ€å®¹é”™ï¼šåŸºäºäºŒé¡¹åˆ†å¸ƒæ ‡å‡†è¯¯å·®çš„ 95% ç½®ä¿¡åŒºé—´
        # moe(p) = 1.96 * sqrt(p*(1-p)/n)
        effective_margin = margin_of_error
        if total_requests > 0 and expected_dist:
            import math
            dynamic_margins = []
            for p in expected_dist.values():
                p = max(0.0, min(1.0, float(p)))
                se = math.sqrt(p * (1.0 - p) / total_requests)
                moe = 1.96 * se
                dynamic_margins.append(moe)
            # ä½¿ç”¨æœ€ä¿å®ˆï¼ˆæœ€å¤§çš„ï¼‰åŠ¨æ€å®¹é”™ï¼Œå¹¶ç•™å°‘é‡ç¼“å†²
            dynamic_margin = max(dynamic_margins) if dynamic_margins else 0.0
            # åŠ  1% ç¼“å†²ï¼Œé¿å…è¾¹ç•ŒæŠ–åŠ¨
            effective_margin = max(margin_of_error, dynamic_margin + 0.01)
        
        # ä½¿ç”¨ï¼ˆå¯èƒ½æ”¾å®½çš„ï¼‰å®¹é”™è¿›è¡ŒéªŒè¯
        weight_verification = self.log_parser.verify_weight_distribution(
            distribution_result, expected_dist, effective_margin
        )
        # æ ‡æ³¨å®é™…ä½¿ç”¨çš„å®¹é”™
        weight_verification['configured_margin_of_error'] = margin_of_error
        weight_verification['effective_margin_of_error'] = effective_margin
        
        status = VerificationStatus.PASSED if weight_verification['overall_passed'] else VerificationStatus.FAILED
        
        return VerificationResult(
            test_name="æµé‡åˆ†å¸ƒéªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=expected_dist,
            actual_value=distribution_result['version_percentages'],
            deviation=self._calculate_distribution_deviation(expected_dist, distribution_result['version_percentages']),
            message=weight_verification['summary'],
            details=weight_verification
        )
    
    def _verify_fault_injection(self, case_id: str, expected_behavior: ExpectedBehavior,
                              parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯æ•…éšœæ³¨å…¥"""
        expected_fault_rate = expected_behavior.expected_fault_rate
        expected_fault_code = expected_behavior.expected_fault_code
        
        # ç»Ÿè®¡æ‰€æœ‰æ—¥å¿—æ¡ç›®
        all_entries = []
        for entries in parsed_logs.values():
            all_entries.extend(entries)
        
        if not all_entries:
            return VerificationResult(
                test_name="æ•…éšœæ³¨å…¥éªŒè¯",
                case_id=case_id,
                status=VerificationStatus.FAILED,
                expected_value=expected_fault_rate,
                actual_value=0,
                message="æœªæ‰¾åˆ°ä»»ä½•æ—¥å¿—æ¡ç›®"
            )
        
        # è®¡ç®—å®é™…æ•…éšœç‡
        fault_entries = []
        if expected_fault_code:
            fault_entries = [e for e in all_entries if e.status_code == expected_fault_code]
        else:
            fault_entries = [e for e in all_entries if e.is_error]
        
        actual_fault_rate = len(fault_entries) / len(all_entries)
        
        # åˆ¤æ–­æ˜¯å¦ç¬¦åˆæœŸæœ›
        if expected_fault_rate is not None:
            deviation = abs(actual_fault_rate - expected_fault_rate)
            tolerance = 0.1  # 10% å®¹é”™
            
            if deviation <= tolerance:
                status = VerificationStatus.PASSED
                message = f"æ•…éšœç‡ç¬¦åˆé¢„æœŸ: {actual_fault_rate:.2%} â‰ˆ {expected_fault_rate:.2%}"
            else:
                status = VerificationStatus.FAILED
                message = f"æ•…éšœç‡åå·®è¿‡å¤§: {actual_fault_rate:.2%} vs {expected_fault_rate:.2%}"
        else:
            # æ²¡æœ‰æœŸæœ›æ•…éšœç‡ï¼Œåªæ£€æŸ¥æ˜¯å¦æœ‰æ•…éšœ
            if fault_entries:
                status = VerificationStatus.PASSED
                message = f"æ£€æµ‹åˆ°æ•…éšœæ³¨å…¥ç”Ÿæ•ˆ: {len(fault_entries)} ä¸ªæ•…éšœè¯·æ±‚"
            else:
                status = VerificationStatus.WARNING
                message = "æœªæ£€æµ‹åˆ°æ•…éšœæ³¨å…¥æ•ˆæœ"
        
        return VerificationResult(
            test_name="æ•…éšœæ³¨å…¥éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=expected_fault_rate,
            actual_value=actual_fault_rate,
            deviation=abs(actual_fault_rate - (expected_fault_rate or 0)),
            message=message,
            details={
                'total_requests': len(all_entries),
                'fault_requests': len(fault_entries),
                'expected_fault_code': expected_fault_code,
                'fault_status_codes': [e.status_code for e in fault_entries]
            }
        )
    
    def _verify_retry(self, case_id: str, expected_behavior: ExpectedBehavior,
                     parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯é‡è¯•è¡Œä¸ºï¼ŒåŒ…æ‹¬æ—¶é—´åˆ†æï¼ˆæ”¯æŒGatewayæ—¥å¿—ï¼‰"""
        # åˆ†ç¦»Gatewayå’ŒSidecaræ—¥å¿—
        gateway_entries = []
        sidecar_entries = []
        all_entries = []
        
        for pod_name, entries in parsed_logs.items():
            for entry in entries:
                all_entries.append(entry)
                if hasattr(entry, 'log_source'):
                    if entry.log_source == "gateway" or "gateway" in pod_name.lower():
                        gateway_entries.append(entry)
                    else:
                        sidecar_entries.append(entry)
                else:
                    # å…¼å®¹è€ç‰ˆæœ¬LogEntry
                    if "gateway" in pod_name.lower():
                        gateway_entries.append(entry)
                    else:
                        sidecar_entries.append(entry)
        
        if not all_entries:
            return VerificationResult(
                test_name="é‡è¯•éªŒè¯",
                case_id=case_id,
                status=VerificationStatus.FAILED,
                expected_value="é‡è¯•è¡Œä¸º",
                actual_value="æ— æ—¥å¿—",
                message="æœªæ‰¾åˆ°ä»»ä½•æ—¥å¿—æ¡ç›®"
            )
        
        print(f"ğŸ“Š é‡è¯•éªŒè¯ - Gatewayæ—¥å¿—: {len(gateway_entries)}æ¡, Sidecaræ—¥å¿—: {len(sidecar_entries)}æ¡")
        
        # ä¼˜å…ˆä½¿ç”¨Gatewayæ—¥å¿—è¿›è¡Œé‡è¯•åˆ†æ
        primary_entries = gateway_entries if gateway_entries else all_entries
        
        # åˆ†æé‡è¯•æ¨¡å¼
        # 1. æ£€æŸ¥é”™è¯¯æ¡ç›®ï¼ˆå¯èƒ½è§¦å‘é‡è¯•ï¼‰
        error_entries = [e for e in all_entries if e.is_error]
        success_entries = [e for e in all_entries if e.is_success]
        
        # 2. åˆ†æå“åº”æ—¶é—´åˆ†å¸ƒï¼Œå¯»æ‰¾é‡è¯•å»¶è¿Ÿç‰¹å¾
        response_times = [e.request_time for e in all_entries if e.request_time > 0]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„é‡è¯•å»¶è¿Ÿï¼ˆæ¯”æ­£å¸¸è¯·æ±‚æ…¢å¾ˆå¤šï¼‰
        if response_times:
            response_times.sort()
            p95_time = response_times[int(len(response_times) * 0.95)] if len(response_times) > 20 else max(response_times)
            p50_time = response_times[len(response_times) // 2]
            
            # å¦‚æœ95%åˆ†ä½æ•°æ¯”ä¸­ä½æ•°å¤§å¾ˆå¤šï¼Œå¯èƒ½æœ‰é‡è¯•
            time_variance_ratio = p95_time / p50_time if p50_time > 0 else 1
        else:
            time_variance_ratio = 1
            p95_time = 0
            p50_time = 0
        
        # 4. é‡è¯•åˆ¤æ–­é€»è¾‘
        retry_detected = False
        retry_indicators = []
        
        # æ£€æŸ¥å“åº”æ—¶é—´åˆ†å¸ƒå¼‚å¸¸ï¼ˆé‡è¯•å¯¼è‡´çš„å»¶è¿Ÿï¼‰
        if time_variance_ratio > 3:  # 95%åˆ†ä½æ•°æ¯”ä¸­ä½æ•°å¤§3å€ä»¥ä¸Š
            retry_detected = True
            retry_indicators.append(f"å“åº”æ—¶é—´åˆ†å¸ƒå¼‚å¸¸ (P95/P50={time_variance_ratio:.1f})")
        
        # æ£€æŸ¥é”™è¯¯ç‡ä¸æœ€ç»ˆæˆåŠŸç‡çš„å…³ç³»
        if error_entries and success_entries:
            initial_error_rate = len(error_entries) / len(all_entries)
            if 0.1 < initial_error_rate < 0.8:  # æœ‰ä¸€å®šé”™è¯¯ä½†ä¸æ˜¯å…¨éƒ¨å¤±è´¥ï¼Œå¯èƒ½æœ‰é‡è¯•æˆåŠŸ
                retry_detected = True
                retry_indicators.append(f"éƒ¨åˆ†é”™è¯¯åæˆåŠŸ (é”™è¯¯ç‡{initial_error_rate:.1%})")
        
        # æ£€æŸ¥æœŸæœ›çš„é‡è¯•é…ç½®
        expected_max_retries = getattr(expected_behavior, 'expected_max_retries', None)
        expected_retry_timeout = getattr(expected_behavior, 'expected_retry_timeout', None)
        
        # æ—¶é—´éªŒè¯
        time_validation_passed = True
        time_message = ""
        
        if expected_retry_timeout and avg_response_time > 0:
            # æ£€æŸ¥å¹³å‡å“åº”æ—¶é—´æ˜¯å¦åœ¨é¢„æœŸèŒƒå›´å†…
            if avg_response_time > expected_retry_timeout * 1.5:  # å…è®¸50%å®¹é”™
                time_validation_passed = False
                time_message = f"å“åº”æ—¶é—´è¶…å‡ºé¢„æœŸ ({avg_response_time:.3f}s > {expected_retry_timeout * 1.5:.3f}s)"
            else:
                time_message = f"å“åº”æ—¶é—´åœ¨é¢„æœŸèŒƒå›´å†… ({avg_response_time:.3f}s)"
        
        # ç»¼åˆåˆ¤æ–­
        if retry_detected and time_validation_passed:
            status = VerificationStatus.PASSED
            message = f"æ£€æµ‹åˆ°é‡è¯•è¡Œä¸º: {', '.join(retry_indicators)}"
            if time_message:
                message += f"; {time_message}"
        elif retry_detected and not time_validation_passed:
            status = VerificationStatus.WARNING
            message = f"æ£€æµ‹åˆ°é‡è¯•ä½†æ—¶é—´å¼‚å¸¸: {', '.join(retry_indicators)}; {time_message}"
        elif not retry_detected:
            status = VerificationStatus.WARNING
            message = f"æœªæ˜ç¡®æ£€æµ‹åˆ°é‡è¯•è¡Œä¸ºï¼Œå¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s"
        else:
            status = VerificationStatus.FAILED
            message = "é‡è¯•éªŒè¯å¤±è´¥"
        
        return VerificationResult(
            test_name="é‡è¯•éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value="é‡è¯•è¡Œä¸º",
            actual_value=f"{len(retry_indicators)} ä¸ªé‡è¯•æŒ‡æ ‡",
            message=message,
            details={
                'total_requests': len(all_entries),
                'error_requests': len(error_entries),
                'success_requests': len(success_entries),
                'avg_response_time': avg_response_time,
                'p95_response_time': p95_time,
                'p50_response_time': p50_time,
                'time_variance_ratio': time_variance_ratio,
                'retry_indicators': retry_indicators,
                'time_validation_passed': time_validation_passed,
                'expected_max_retries': expected_max_retries,
                'expected_retry_timeout': expected_retry_timeout
            }
        )
    
    def _verify_circuit_breaker(self, case_id: str, expected_behavior: ExpectedBehavior,
                              parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯ç†”æ–­å™¨è¡Œä¸ºï¼ŒåŒ…æ‹¬æ—¶é—´åˆ†æï¼ˆæ”¯æŒGatewayæ—¥å¿—ï¼‰"""
        # åˆ†ç¦»Gatewayå’ŒSidecaræ—¥å¿—
        gateway_entries = []
        sidecar_entries = []
        all_entries = []
        
        for pod_name, entries in parsed_logs.items():
            for entry in entries:
                all_entries.append(entry)
                if hasattr(entry, 'log_source'):
                    if entry.log_source == "gateway" or "gateway" in pod_name.lower():
                        gateway_entries.append(entry)
                    else:
                        sidecar_entries.append(entry)
                else:
                    # å…¼å®¹è€ç‰ˆæœ¬LogEntry
                    if "gateway" in pod_name.lower():
                        gateway_entries.append(entry)
                    else:
                        sidecar_entries.append(entry)
        
        if not all_entries:
            return VerificationResult(
                test_name="ç†”æ–­å™¨éªŒè¯",
                case_id=case_id,
                status=VerificationStatus.FAILED,
                expected_value="ç†”æ–­è¡Œä¸º",
                actual_value="æ— æ—¥å¿—",
                message="æœªæ‰¾åˆ°ä»»ä½•æ—¥å¿—æ¡ç›®"
            )
        
        print(f"ğŸ“Š ç†”æ–­å™¨éªŒè¯ - Gatewayæ—¥å¿—: {len(gateway_entries)}æ¡, Sidecaræ—¥å¿—: {len(sidecar_entries)}æ¡")
        
        # æŒ‰æ—¶é—´æ’åºï¼Œåˆ†æç†”æ–­æ—¶é—´æ¨¡å¼
        all_entries.sort(key=lambda e: e.timestamp)
        gateway_entries.sort(key=lambda e: e.timestamp)
        sidecar_entries.sort(key=lambda e: e.timestamp)
        
        # åˆ†æé”™è¯¯æ¨¡å¼ï¼Œå¯»æ‰¾ç†”æ–­ç‰¹å¾ï¼ˆä¼˜å…ˆä½¿ç”¨Gatewayæ—¥å¿—ï¼‰
        primary_entries = gateway_entries if gateway_entries else all_entries
        error_entries = [e for e in primary_entries if e.is_error]
        success_entries = [e for e in primary_entries if e.is_success]
        
        # æ£€æŸ¥ç†”æ–­å™¨ç›¸å…³çš„é”™è¯¯ï¼Œåˆ©ç”¨response_flags
        circuit_breaker_errors = []
        upstream_overflow_errors = []  # UOæ ‡å¿—
        upstream_connection_errors = []  # UH, UC, UFæ ‡å¿—
        
        for entry in error_entries:
            if entry.status_code == 503:
                circuit_breaker_errors.append(entry)
                # æ£€æŸ¥response_flagsæ¥è¯†åˆ«å…·ä½“çš„ç†”æ–­ç±»å‹
                if hasattr(entry, 'response_flags'):
                    if entry.response_flags == 'UO':
                        upstream_overflow_errors.append(entry)
                    elif entry.response_flags in ['UH', 'UC', 'UF']:
                        upstream_connection_errors.append(entry)
        
        print(f"ğŸ” ç†”æ–­åˆ†æ - 503é”™è¯¯: {len(circuit_breaker_errors)}ä¸ª, UOæº¢å‡º: {len(upstream_overflow_errors)}ä¸ª, è¿æ¥é”™è¯¯: {len(upstream_connection_errors)}ä¸ª")
        
        # è®¡ç®—é”™è¯¯ç‡
        error_rate = len(error_entries) / len(all_entries)
        
        # æ—¶é—´åˆ†æï¼šæ£€æŸ¥ç†”æ–­å¼€å¯å’Œæ¢å¤æ¨¡å¼
        time_analysis = self._analyze_circuit_breaker_timing(all_entries, error_entries, circuit_breaker_errors)
        
        # æ£€æŸ¥æœŸæœ›çš„ç†”æ–­é…ç½®
        expected_trip_threshold = getattr(expected_behavior, 'expected_trip_threshold', None)
        expected_trip_timeout = getattr(expected_behavior, 'expected_trip_timeout', None)
        expected_recovery_time = getattr(expected_behavior, 'expected_recovery_time', None)
        
        # æ—¶é—´éªŒè¯
        time_validation_results = []
        
        # éªŒè¯ç†”æ–­è§¦å‘æ—¶é—´
        if expected_trip_timeout and time_analysis.get('trip_detection_time'):
            trip_time = time_analysis['trip_detection_time']
            if trip_time <= expected_trip_timeout * 1.2:  # å…è®¸20%å®¹é”™
                time_validation_results.append(f"ç†”æ–­è§¦å‘æ—¶é—´æ­£å¸¸ ({trip_time:.3f}s)")
            else:
                time_validation_results.append(f"ç†”æ–­è§¦å‘æ—¶é—´è¿‡é•¿ ({trip_time:.3f}s > {expected_trip_timeout * 1.2:.3f}s)")
        
        # éªŒè¯æ¢å¤æ—¶é—´
        if expected_recovery_time and time_analysis.get('recovery_time'):
            recovery_time = time_analysis['recovery_time']
            if recovery_time <= expected_recovery_time * 1.2:  # å…è®¸20%å®¹é”™
                time_validation_results.append(f"æ¢å¤æ—¶é—´æ­£å¸¸ ({recovery_time:.3f}s)")
            else:
                time_validation_results.append(f"æ¢å¤æ—¶é—´è¿‡é•¿ ({recovery_time:.3f}s > {expected_recovery_time * 1.2:.3f}s)")
        
        # ç»¼åˆç†”æ–­åˆ¤æ–­é€»è¾‘
        circuit_breaker_detected = False
        cb_indicators = []
        
        # æ£€æŸ¥503é”™è¯¯å’Œé”™è¯¯ç‡
        if circuit_breaker_errors and error_rate > 0.1:  # è¶…è¿‡ 10% é”™è¯¯ç‡ä¸”æœ‰ 503
            circuit_breaker_detected = True
            cb_indicators.append(f"{len(circuit_breaker_errors)} ä¸ª503é”™è¯¯")
        
        # æ£€æŸ¥é”™è¯¯èšé›†æ¨¡å¼ï¼ˆç†”æ–­ç‰¹å¾ï¼‰
        if time_analysis.get('error_clustering_detected'):
            circuit_breaker_detected = True
            cb_indicators.append("é”™è¯¯èšé›†æ¨¡å¼")
        
        # æ£€æŸ¥å¿«é€Ÿå¤±è´¥æ¨¡å¼ï¼ˆç†”æ–­åçš„å¿«é€Ÿæ‹’ç»ï¼‰
        if time_analysis.get('fast_fail_detected'):
            circuit_breaker_detected = True
            cb_indicators.append("å¿«é€Ÿå¤±è´¥æ¨¡å¼")
        
        # æ—¶é—´éªŒè¯é€šè¿‡æƒ…å†µ
        time_validation_passed = all("æ­£å¸¸" in result for result in time_validation_results)
        
        # ç»¼åˆåˆ¤æ–­
        if circuit_breaker_detected and time_validation_passed:
            status = VerificationStatus.PASSED
            message = f"æ£€æµ‹åˆ°ç†”æ–­è¡Œä¸º: {', '.join(cb_indicators)}"
            if time_validation_results:
                message += f"; æ—¶é—´éªŒè¯: {', '.join(time_validation_results)}"
        elif circuit_breaker_detected and not time_validation_passed:
            status = VerificationStatus.WARNING
            message = f"æ£€æµ‹åˆ°ç†”æ–­ä½†æ—¶é—´å¼‚å¸¸: {', '.join(cb_indicators)}; {', '.join(time_validation_results)}"
        elif error_rate > 0.5:  # é”™è¯¯ç‡è¶…è¿‡ 50%
            status = VerificationStatus.WARNING
            message = f"é«˜é”™è¯¯ç‡å¯èƒ½è¡¨ç¤ºç†”æ–­: {error_rate:.2%}"
        else:
            status = VerificationStatus.WARNING
            message = f"æœªæ˜ç¡®æ£€æµ‹åˆ°ç†”æ–­è¡Œä¸ºï¼Œé”™è¯¯ç‡: {error_rate:.2%}"
        
        return VerificationResult(
            test_name="ç†”æ–­å™¨éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value="ç†”æ–­è¡Œä¸º",
            actual_value=f"{error_rate:.2%} é”™è¯¯ç‡, {len(cb_indicators)} ä¸ªæŒ‡æ ‡",
            message=message,
            details={
                'total_requests': len(all_entries),
                'error_requests': len(error_entries),
                'circuit_breaker_errors': len(circuit_breaker_errors),
                'error_rate': error_rate,
                'cb_indicators': cb_indicators,
                'time_analysis': time_analysis,
                'time_validation_results': time_validation_results,
                'time_validation_passed': time_validation_passed,
                'expected_trip_threshold': expected_trip_threshold,
                'expected_trip_timeout': expected_trip_timeout,
                'expected_recovery_time': expected_recovery_time
            }
        )
    
    def _analyze_circuit_breaker_timing(self, all_entries: List[LogEntry], 
                                       error_entries: List[LogEntry], 
                                       cb_errors: List[LogEntry]) -> Dict[str, Any]:
        """åˆ†æç†”æ–­å™¨æ—¶é—´æ¨¡å¼"""
        if not all_entries:
            return {}
        
        analysis = {}
        
        # æ£€æµ‹é”™è¯¯èšé›†ï¼ˆè¿ç»­é”™è¯¯è¡¨ç¤ºç†”æ–­è§¦å‘ï¼‰
        error_clustering_detected = False
        consecutive_errors = 0
        max_consecutive_errors = 0
        
        for entry in all_entries:
            if entry.is_error:
                consecutive_errors += 1
                max_consecutive_errors = max(max_consecutive_errors, consecutive_errors)
            else:
                consecutive_errors = 0
        
        if max_consecutive_errors >= 5:  # è¿ç»­5ä¸ªä»¥ä¸Šé”™è¯¯
            error_clustering_detected = True
        
        analysis['error_clustering_detected'] = error_clustering_detected
        analysis['max_consecutive_errors'] = max_consecutive_errors
        
        # æ£€æµ‹å¿«é€Ÿå¤±è´¥ï¼ˆ503é”™è¯¯å“åº”æ—¶é—´å¾ˆçŸ­ï¼‰
        fast_fail_detected = False
        if cb_errors:
            cb_response_times = [e.request_time for e in cb_errors if e.request_time > 0]
            if cb_response_times:
                avg_cb_time = sum(cb_response_times) / len(cb_response_times)
                # ç†”æ–­å™¨å¿«é€Ÿå¤±è´¥é€šå¸¸å“åº”æ—¶é—´å¾ˆçŸ­
                if avg_cb_time < 0.1:  # å°äº100msè®¤ä¸ºæ˜¯å¿«é€Ÿå¤±è´¥
                    fast_fail_detected = True
                analysis['avg_cb_response_time'] = avg_cb_time
        
        analysis['fast_fail_detected'] = fast_fail_detected
        
        # åˆ†æç†”æ–­è§¦å‘æ—¶é—´ï¼ˆç¬¬ä¸€ä¸ªé”™è¯¯åˆ°ç†”æ–­å¼€å¯çš„æ—¶é—´ï¼‰
        if error_entries and cb_errors:
            try:
                from datetime import datetime
                # å°†æ—¶é—´æˆ³å­—ç¬¦ä¸²è½¬æ¢ä¸ºdatetimeå¯¹è±¡
                error_times = []
                cb_times = []
                
                for e in error_entries:
                    try:
                        # æ”¯æŒå¤šç§æ—¶é—´æ ¼å¼
                        if 'T' in e.timestamp:
                            time_obj = datetime.fromisoformat(e.timestamp.replace('Z', '+00:00'))
                        else:
                            time_obj = datetime.strptime(e.timestamp, '%Y-%m-%d %H:%M:%S')
                        error_times.append(time_obj)
                    except:
                        continue
                
                for e in cb_errors:
                    try:
                        if 'T' in e.timestamp:
                            time_obj = datetime.fromisoformat(e.timestamp.replace('Z', '+00:00'))
                        else:
                            time_obj = datetime.strptime(e.timestamp, '%Y-%m-%d %H:%M:%S')
                        cb_times.append(time_obj)
                    except:
                        continue
                
                if error_times and cb_times:
                    first_error_time = min(error_times)
                    first_cb_time = min(cb_times)
                    trip_detection_time = (first_cb_time - first_error_time).total_seconds()
                    analysis['trip_detection_time'] = max(0, trip_detection_time)
            except Exception as e:
                print(f"âš ï¸ æ—¶é—´è§£æé”™è¯¯: {e}")
                analysis['trip_detection_time'] = 0
        
        # åˆ†ææ¢å¤æ—¶é—´ï¼ˆæœ€åä¸€ä¸ªç†”æ–­é”™è¯¯åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸè¯·æ±‚çš„æ—¶é—´ï¼‰
        if cb_errors and all_entries:
            try:
                # è½¬æ¢æ—¶é—´æˆ³ä¸ºdatetimeå¯¹è±¡
                cb_times = []
                for e in cb_errors:
                    try:
                        if 'T' in e.timestamp:
                            time_obj = datetime.fromisoformat(e.timestamp.replace('Z', '+00:00'))
                        else:
                            time_obj = datetime.strptime(e.timestamp, '%Y-%m-%d %H:%M:%S')
                        cb_times.append((time_obj, e))
                    except:
                        continue
                
                if cb_times:
                    last_cb_time_obj, _ = max(cb_times, key=lambda x: x[0])
                    
                    # æ‰¾åˆ°ç†”æ–­åçš„æˆåŠŸè¯·æ±‚
                    success_times = []
                    for e in all_entries:
                        if e.is_success:
                            try:
                                if 'T' in e.timestamp:
                                    time_obj = datetime.fromisoformat(e.timestamp.replace('Z', '+00:00'))
                                else:
                                    time_obj = datetime.strptime(e.timestamp, '%Y-%m-%d %H:%M:%S')
                                if time_obj > last_cb_time_obj:
                                    success_times.append(time_obj)
                            except:
                                continue
                    
                    if success_times:
                        first_success_time = min(success_times)
                        recovery_time = (first_success_time - last_cb_time_obj).total_seconds()
                        analysis['recovery_time'] = recovery_time
            except Exception as e:
                print(f"âš ï¸ æ¢å¤æ—¶é—´è§£æé”™è¯¯: {e}")
                analysis['recovery_time'] = 0
        
        return analysis
    
    def _verify_performance_metrics(self, case_id: str, expected_behavior: ExpectedBehavior,
                                  parsed_logs: Dict[str, List[LogEntry]]) -> VerificationResult:
        """éªŒè¯æ€§èƒ½æŒ‡æ ‡"""
        # ç»Ÿè®¡æ‰€æœ‰æ—¥å¿—æ¡ç›®
        all_entries = []
        for entries in parsed_logs.values():
            all_entries.extend(entries)
        
        if not all_entries:
            return VerificationResult(
                test_name="æ€§èƒ½æŒ‡æ ‡éªŒè¯",
                case_id=case_id,
                status=VerificationStatus.SKIPPED,
                expected_value=None,
                actual_value=None,
                message="æ— æ—¥å¿—æ•°æ®è¿›è¡Œæ€§èƒ½åˆ†æ"
            )
        
        # è®¡ç®—æˆåŠŸç‡
        success_entries = [e for e in all_entries if e.is_success]
        actual_success_rate = len(success_entries) / len(all_entries)
        
        # ä¸æœŸæœ›æˆåŠŸç‡æ¯”è¾ƒ
        expected_success_rate = expected_behavior.expected_success_rate
        
        if expected_success_rate is not None:
            deviation = abs(actual_success_rate - expected_success_rate)
            tolerance = 0.1  # 10% å®¹é”™
            
            if deviation <= tolerance:
                status = VerificationStatus.PASSED
                message = f"æˆåŠŸç‡ç¬¦åˆé¢„æœŸ: {actual_success_rate:.2%} â‰ˆ {expected_success_rate:.2%}"
            else:
                status = VerificationStatus.WARNING
                message = f"æˆåŠŸç‡åå·®: {actual_success_rate:.2%} vs {expected_success_rate:.2%}"
        else:
            # æ²¡æœ‰æœŸæœ›æˆåŠŸç‡ï¼Œæ ¹æ®ä¸€èˆ¬æ ‡å‡†åˆ¤æ–­
            if actual_success_rate >= 0.95:
                status = VerificationStatus.PASSED
                message = f"æˆåŠŸç‡è‰¯å¥½: {actual_success_rate:.2%}"
            elif actual_success_rate >= 0.8:
                status = VerificationStatus.WARNING
                message = f"æˆåŠŸç‡ä¸€èˆ¬: {actual_success_rate:.2%}"
            else:
                status = VerificationStatus.WARNING
                message = f"æˆåŠŸç‡è¾ƒä½: {actual_success_rate:.2%}"
        
        return VerificationResult(
            test_name="æ€§èƒ½æŒ‡æ ‡éªŒè¯",
            case_id=case_id,
            status=status,
            expected_value=expected_success_rate,
            actual_value=actual_success_rate,
            deviation=deviation if expected_success_rate else None,
            message=message,
            details={
                'total_requests': len(all_entries),
                'success_requests': len(success_entries),
                'success_rate': actual_success_rate
            }
        )
    
    def _calculate_overall_status(self, individual_results: List[VerificationResult]) -> VerificationStatus:
        """
        è®¡ç®—ç»¼åˆçŠ¶æ€ - ä»»ä¸€ç»´åº¦é€šè¿‡å³åˆ¤å®šä¸ºé€šè¿‡ï¼›å¦åˆ™è‹¥æœ‰å‘Šè­¦åˆ™ä¸ºå‘Šè­¦ï¼Œå¦åˆ™å¤±è´¥ã€‚
        åŒæ—¶å„ç»´åº¦è¯¦ç»†çŠ¶æ€ä¼šåœ¨æŠ¥å‘Šä¸­å±•ç¤ºã€‚
        """
        if not individual_results:
            return VerificationStatus.SKIPPED

        # ä»»ä¸€ç»´åº¦é€šè¿‡å³åˆæ³•
        if any(r.status == VerificationStatus.PASSED for r in individual_results):
            return VerificationStatus.PASSED
        # å…¶æ¬¡è‹¥å­˜åœ¨å‘Šè­¦
        if any(r.status == VerificationStatus.WARNING for r in individual_results):
            return VerificationStatus.WARNING
        # å¦åˆ™å¤±è´¥
        return VerificationStatus.FAILED

    def _calculate_overall_status_policy_aware(self, expected_behavior: ExpectedBehavior,
                                              individual_results: List[VerificationResult]) -> VerificationStatus:
        """
        åŸºäºç­–ç•¥ç±»å‹çš„å®šåˆ¶ç»¼åˆåˆ¤å®šï¼š
        - è·¯ç”±: åªè¦ HTTP çŠ¶æ€éªŒè¯é€šè¿‡å³å¯è®¤ä¸ºé€šè¿‡ï¼ˆæ—¥å¿—ç»´åº¦ä»…ä½œå‚è€ƒï¼‰
        - æµé‡åˆ†å¸ƒ: å¿…é¡»æµé‡åˆ†å¸ƒéªŒè¯é€šè¿‡ï¼›HTTP ä½œä¸ºåŸºç¡€å¥åº·åˆ¤æ–­
        - æ•…éšœæ³¨å…¥: ä»¥ HTTP ç›®æ ‡æ•…éšœç /æˆåŠŸç‡ä¸ºä¸»ï¼Œæ—¥å¿—è¾…åŠ©
        - ç†”æ–­/é‡è¯•: å…è®¸ä¸€å®šé”™è¯¯ç‡ï¼ŒHTTPä¸æ€§èƒ½/é”™è¯¯ç‡éªŒè¯ç»“åˆ
        """
        # æ˜ å°„ä¾¿äºæŸ¥æ‰¾
        result_by_name = {r.test_name: r for r in individual_results}

        policy = expected_behavior.policy_type
        http_ok = result_by_name.get("HTTPçŠ¶æ€ç éªŒè¯") and result_by_name["HTTPçŠ¶æ€ç éªŒè¯"].status == VerificationStatus.PASSED
        dist_res = result_by_name.get("æµé‡åˆ†å¸ƒéªŒè¯") or result_by_name.get("æµé‡åˆ†å¸ƒ")
        route_res = result_by_name.get("è·¯ç”±éªŒè¯")
        perf_res = result_by_name.get("æ€§èƒ½æŒ‡æ ‡éªŒè¯")

        if policy.name.lower() == 'routing':
            # è·¯ç”±éªŒè¯å¿…é¡»æœ‰æ—¥å¿—éªŒè¯é€šè¿‡æ‰èƒ½é€šè¿‡ï¼ŒHTTPéªŒè¯é€šè¿‡ä¸ç®—
            route_ok = route_res and route_res.status == VerificationStatus.PASSED
            if route_ok:
                return VerificationStatus.PASSED
            elif http_ok and not route_ok:
                # HTTPé€šè¿‡ä½†è·¯ç”±æ—¥å¿—éªŒè¯æœªé€šè¿‡ï¼Œç»™è­¦å‘Š
                return VerificationStatus.WARNING
            else:
                return VerificationStatus.FAILED

        if policy.name.lower() == 'traffic_split':
            # å¿…é¡»åˆ†å¸ƒéªŒè¯é€šè¿‡
            if dist_res and dist_res.status == VerificationStatus.PASSED:
                return VerificationStatus.PASSED
            # åˆ†å¸ƒæœªé€šè¿‡ä½†HTTPé€šè¿‡ â†’ è­¦å‘Š
            if http_ok:
                return VerificationStatus.WARNING
            return VerificationStatus.FAILED

        if policy.name.lower() == 'retry':
            # é‡è¯•éªŒè¯éœ€è¦é‡è¯•è¡Œä¸ºå’Œæ—¶é—´éªŒè¯éƒ½é€šè¿‡
            retry_res = result_by_name.get("é‡è¯•éªŒè¯")
            if retry_res and retry_res.status == VerificationStatus.PASSED:
                return VerificationStatus.PASSED
            elif retry_res and retry_res.status == VerificationStatus.WARNING:
                return VerificationStatus.WARNING
            elif http_ok:  # é‡è¯•éªŒè¯å¤±è´¥ä½†HTTPé€šè¿‡ï¼Œç»™è­¦å‘Š
                return VerificationStatus.WARNING
            else:
                return VerificationStatus.FAILED
        
        if policy.name.lower() == 'circuit_breaker':
            # ç†”æ–­éªŒè¯éœ€è¦ç†”æ–­è¡Œä¸ºå’Œæ—¶é—´éªŒè¯éƒ½é€šè¿‡
            cb_res = result_by_name.get("ç†”æ–­å™¨éªŒè¯")
            if cb_res and cb_res.status == VerificationStatus.PASSED:
                return VerificationStatus.PASSED
            elif cb_res and cb_res.status == VerificationStatus.WARNING:
                return VerificationStatus.WARNING
            elif http_ok:  # ç†”æ–­éªŒè¯å¤±è´¥ä½†HTTPé€šè¿‡ï¼Œç»™è­¦å‘Š
                return VerificationStatus.WARNING
            else:
                return VerificationStatus.FAILED
        
        if policy.name.lower() == 'fault_injection':
            # æ•…éšœæ³¨å…¥ä¼˜å…ˆHTTPï¼Œç»“åˆæ€§èƒ½/é”™è¯¯ç‡
            if http_ok:
                # å¦‚æœæœ‰æ€§èƒ½æŒ‡æ ‡ï¼Œå¤±è´¥åˆ™è­¦å‘Š
                if perf_res and perf_res.status == VerificationStatus.FAILED:
                    return VerificationStatus.WARNING
                return VerificationStatus.PASSED
            # HTTPä¸é€šè¿‡ï¼Œè‹¥æ€§èƒ½/å…¶ä»–æœ‰é€šè¿‡ï¼Œç»™è­¦å‘Šï¼Œå¦åˆ™å¤±è´¥
            if any(r.status == VerificationStatus.PASSED for r in individual_results):
                return VerificationStatus.WARNING
            return VerificationStatus.FAILED

        # å…¶å®ƒç­–ç•¥ä½¿ç”¨é€šç”¨è§„åˆ™
        return self._calculate_overall_status(individual_results)
    
    def _generate_metrics_summary(self, parsed_logs: Dict[str, List[LogEntry]]) -> Dict[str, Any]:
        """ç”ŸæˆæŒ‡æ ‡æ‘˜è¦"""
        total_requests = sum(len(entries) for entries in parsed_logs.values())
        total_pods = len(parsed_logs)
        
        # ç»Ÿè®¡æ‰€æœ‰æ¡ç›®
        all_entries = []
        for entries in parsed_logs.values():
            all_entries.extend(entries)
        
        success_count = sum(1 for e in all_entries if e.is_success)
        error_count = sum(1 for e in all_entries if e.is_error)
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [e.request_time for e in all_entries if e.request_time > 0]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            'total_requests': total_requests,
            'total_pods': total_pods,
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': success_count / total_requests if total_requests > 0 else 0,
            'error_rate': error_count / total_requests if total_requests > 0 else 0,
            'avg_response_time': avg_response_time,
            'pods_with_traffic': [pod for pod, entries in parsed_logs.items() if entries]
        }
    
    def _generate_summary(self, expected_behavior: ExpectedBehavior,
                         individual_results: List[VerificationResult],
                         metrics: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤šç»´åº¦éªŒè¯æ‘˜è¦"""
        passed_count = sum(1 for r in individual_results if r.is_passed)
        total_count = len(individual_results)
        
        # æŒ‰éªŒè¯ç±»å‹åˆ†ç±»
        http_results = [r for r in individual_results if r.test_name == "HTTPçŠ¶æ€ç éªŒè¯"]
        basic_results = [r for r in individual_results if r.test_name == "åŸºæœ¬æŒ‡æ ‡éªŒè¯"]
        other_results = [r for r in individual_results if r.test_name not in ["HTTPçŠ¶æ€ç éªŒè¯", "åŸºæœ¬æŒ‡æ ‡éªŒè¯"]]
        
        summary_parts = [
            f"éªŒè¯å®Œæˆ: {passed_count}/{total_count} é¡¹é€šè¿‡",
            f"æ€»è¯·æ±‚: {metrics['total_requests']}",
            f"æˆåŠŸç‡: {metrics['success_rate']:.2%}"
        ]
        
        # æ·»åŠ å¤šç»´åº¦éªŒè¯çŠ¶æ€
        dimension_status = []
        if http_results:
            http_status = "âœ…" if http_results[0].is_passed else "âŒ"
            dimension_status.append(f"HTTPéªŒè¯{http_status}")
        
        if basic_results:
            basic_status = "âœ…" if basic_results[0].is_passed else "âŒ"
            dimension_status.append(f"æ—¥å¿—éªŒè¯{basic_status}")
        
        if other_results:
            other_passed = sum(1 for r in other_results if r.is_passed)
            other_total = len(other_results)
            other_status = "âœ…" if other_passed == other_total else "âš ï¸" if other_passed > 0 else "âŒ"
            dimension_status.append(f"å…¶ä»–éªŒè¯{other_status}")
        
        if dimension_status:
            summary_parts.append(f"å¤šç»´åº¦éªŒè¯: {', '.join(dimension_status)}")
        
        if expected_behavior.policy_type == PolicyType.TRAFFIC_SPLIT:
            summary_parts.append("æµé‡åˆ†å¸ƒæµ‹è¯•")
        elif expected_behavior.policy_type == PolicyType.ROUTING:
            summary_parts.append("è·¯ç”±æµ‹è¯•")
        elif expected_behavior.policy_type == PolicyType.FAULT_INJECTION:
            summary_parts.append("æ•…éšœæ³¨å…¥æµ‹è¯•")
        
        return " | ".join(summary_parts)
    
    def _extract_service_name_from_logs(self, parsed_logs: Dict[str, List[LogEntry]]) -> str:
        """ä»æ—¥å¿—ä¸­æå–æœåŠ¡åç§°"""
        if not parsed_logs:
            return "unknown"
        
        # ä»ç¬¬ä¸€ä¸ª pod åç§°æå–æœåŠ¡å
        first_pod = next(iter(parsed_logs.keys()))
        # å‡è®¾ pod åç§°æ ¼å¼ä¸º servicename-version-hash
        parts = first_pod.split('-')
        if len(parts) >= 2:
            return parts[0]
        
        return "unknown"
    
    def _calculate_distribution_deviation(self, expected: Dict[str, float], 
                                        actual: Dict[str, float]) -> float:
        """è®¡ç®—åˆ†å¸ƒåå·®"""
        if not expected or not actual:
            return 1.0
        
        total_deviation = 0.0
        for version, expected_weight in expected.items():
            actual_weight = actual.get(version, 0.0)
            total_deviation += abs(expected_weight - actual_weight)
        
        return total_deviation / len(expected)

# å·¥å…·å‡½æ•°
def compare_batch_results(expected_behaviors: List[ExpectedBehavior],
                         logs_by_case: Dict[str, Dict[str, List[LogEntry]]],
                         comparator: Optional[ResultComparator] = None,
                         http_results_dir: Optional[str] = None) -> List[ComprehensiveResult]:
    """
    æ‰¹é‡æ¯”è¾ƒæµ‹è¯•ç»“æœ
    
    Args:
        expected_behaviors: æœŸæœ›è¡Œä¸ºåˆ—è¡¨
        logs_by_case: {case_id: {pod_name: [LogEntry]}} æ ¼å¼çš„æ—¥å¿—æ•°æ®
        comparator: ç»“æœå¯¹æ¯”å™¨å®ä¾‹
        
    Returns:
        ç»¼åˆéªŒè¯ç»“æœåˆ—è¡¨
    """
    if comparator is None:
        comparator = ResultComparator()
    
    results = []
    
    import os, json, glob

    def load_http_result(case_id: str) -> Optional[Dict[str, Any]]:
        if not http_results_dir:
            return None
        try:
            pattern = os.path.join(http_results_dir, f"{case_id}_http_result_*.json")
            files = glob.glob(pattern)
            if not files:
                return None
            latest = max(files, key=os.path.getctime)
            with open(latest, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('http_result')
        except Exception:
            return None

    for i, behavior in enumerate(expected_behaviors):
        case_id = f"case_{i+1:03d}"  # é»˜è®¤ç”Ÿæˆ case_001, case_002...
        
        if case_id in logs_by_case:
            parsed_logs = logs_by_case[case_id]
            http_result = load_http_result(case_id)
            result = comparator.compare_single_result(case_id, behavior, parsed_logs, http_result)
            results.append(result)
        else:
            # åˆ›å»ºä¸€ä¸ªå¤±è´¥çš„ç»“æœ
            result = ComprehensiveResult(
                case_id=case_id,
                test_description=behavior.description,
                overall_status=VerificationStatus.FAILED,
                individual_results=[],
                summary=f"æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹ {case_id} çš„æ—¥å¿—æ•°æ®",
                metrics={}
            )
            results.append(result)
    
    return results 