#!/usr/bin/env python3
"""
Envoy è®¿é—®æ—¥å¿—è§£æå·¥å…·

ä¸»è¦åŠŸèƒ½ï¼š
1. è§£æ Envoy access log æ¡ç›®
2. ç»Ÿè®¡è¯·æ±‚åˆ†å¸ƒï¼ˆpod å‘½ä¸­æ•°é‡ï¼‰
3. æå–çŠ¶æ€ç ã€å“åº”æ—¶é—´ç­‰æŒ‡æ ‡
4. éªŒè¯æƒé‡åˆ†å¸ƒæ˜¯å¦ç¬¦åˆé¢„æœŸ
"""

import re
import json
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from collections import defaultdict, Counter
import statistics

@dataclass
class LogEntry:
    """å•æ¡è®¿é—®æ—¥å¿—æ¡ç›®"""
    timestamp: str
    method: str
    path: str
    protocol: str
    status_code: int
    response_size: int
    request_time: float
    upstream_host: str
    user_agent: str
    x_forwarded_for: str
    request_id: str
    pod_name: str
    raw_log: str
    
    @property
    def is_success(self) -> bool:
        """åˆ¤æ–­è¯·æ±‚æ˜¯å¦æˆåŠŸ"""
        return 200 <= self.status_code < 400
    
    @property
    def is_error(self) -> bool:
        """åˆ¤æ–­è¯·æ±‚æ˜¯å¦é”™è¯¯"""
        return self.status_code >= 400

class EnvoyLogParser:
    """Envoy è®¿é—®æ—¥å¿—è§£æå™¨"""
    
    # é»˜è®¤çš„ Envoy access log æ ¼å¼æ­£åˆ™è¡¨è¾¾å¼
    # æ ¼å¼: [%START_TIME%] "%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%" 
    #       %RESPONSE_CODE% %RESPONSE_FLAGS% %BYTES_RECEIVED% %BYTES_SENT% %DURATION% 
    #       %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% "%REQ(X-FORWARDED-FOR)%" "%REQ(USER-AGENT)%" 
    #       "%REQ(X-REQUEST-ID)%" "%REQ(:AUTHORITY)%" "%UPSTREAM_HOST%"
    DEFAULT_LOG_PATTERN = re.compile(
        r'\[(?P<timestamp>[^\]]+)\]\s+'
        r'"(?P<method>\w+)\s+(?P<path>[^\s]+)\s+(?P<protocol>[^"]+)"\s+'
        r'(?P<status_code>\d+)\s+(?P<response_flags>[^\s]+)\s+'
        r'(?P<bytes_received>\d+)\s+(?P<bytes_sent>\d+)\s+(?P<duration>\d+)\s+'
        r'(?P<upstream_service_time>[^\s]+)\s+'
        r'"(?P<x_forwarded_for>[^"]*)"\s+'
        r'"(?P<user_agent>[^"]*)"\s+'
        r'"(?P<request_id>[^"]*)"\s+'
        r'"(?P<authority>[^"]*)"\s+'
        r'"(?P<upstream_host>[^"]*)"'
    )
    
    # ç®€åŒ–çš„æ—¥å¿—æ ¼å¼ï¼ˆåªåŒ…å«å…³é”®ä¿¡æ¯ï¼‰
    SIMPLE_LOG_PATTERN = re.compile(
        r'(?P<method>GET|POST|PUT|DELETE|HEAD|OPTIONS)\s+'
        r'(?P<path>/[^\s]*)\s+'
        r'HTTP/[^\s]+.*?'
        r'(?P<status_code>[1-5]\d{2})'
    )
    
    def __init__(self, custom_pattern: Optional[str] = None):
        """
        åˆå§‹åŒ–æ—¥å¿—è§£æå™¨
        
        Args:
            custom_pattern: è‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        """
        if custom_pattern:
            self.log_pattern = re.compile(custom_pattern)
        else:
            self.log_pattern = self.DEFAULT_LOG_PATTERN
    
    def parse_log_entry(self, log_line: str, pod_name: str = "") -> Optional[LogEntry]:
        """
        è§£æå•æ¡è®¿é—®æ—¥å¿—
        
        Args:
            log_line: æ—¥å¿—è¡Œå†…å®¹
            pod_name: æ‰€å± pod åç§°
            
        Returns:
            LogEntry å¯¹è±¡æˆ– Noneï¼ˆè§£æå¤±è´¥ï¼‰
        """
        try:
            # å°è¯•æ ‡å‡†æ ¼å¼è§£æ
            match = self.log_pattern.match(log_line.strip())
            if match:
                data = match.groupdict()
                return LogEntry(
                    timestamp=data.get('timestamp', ''),
                    method=data.get('method', ''),
                    path=data.get('path', ''),
                    protocol=data.get('protocol', ''),
                    status_code=int(data.get('status_code', 0)),
                    response_size=int(data.get('bytes_sent', 0)),
                    request_time=float(data.get('duration', 0)) / 1000.0,  # è½¬æ¢ä¸ºç§’
                    upstream_host=data.get('upstream_host', ''),
                    user_agent=data.get('user_agent', ''),
                    x_forwarded_for=data.get('x_forwarded_for', ''),
                    request_id=data.get('request_id', ''),
                    pod_name=pod_name,
                    raw_log=log_line
                )
            
            # å°è¯•ç®€åŒ–æ ¼å¼è§£æ
            match = self.SIMPLE_LOG_PATTERN.search(log_line)
            if match:
                data = match.groupdict()
                return LogEntry(
                    timestamp=datetime.now().isoformat(),
                    method=data.get('method', ''),
                    path=data.get('path', ''),
                    protocol='HTTP/1.1',
                    status_code=int(data.get('status_code', 0)),
                    response_size=0,
                    request_time=0.0,
                    upstream_host='',
                    user_agent='',
                    x_forwarded_for='',
                    request_id='',
                    pod_name=pod_name,
                    raw_log=log_line
                )
                
        except (ValueError, AttributeError) as e:
            print(f"âš ï¸ è§£ææ—¥å¿—å¤±è´¥: {e}")
            return None
        
        return None
    
    def parse_logs_batch(self, logs_dict: Dict[str, str]) -> Dict[str, List[LogEntry]]:
        """
        æ‰¹é‡è§£æå¤šä¸ª pod çš„æ—¥å¿—
        
        Args:
            logs_dict: {pod_name: log_content} æ ¼å¼çš„æ—¥å¿—å­—å…¸
            
        Returns:
            {pod_name: [LogEntry]} æ ¼å¼çš„è§£æç»“æœ
        """
        parsed_logs = {}
        
        for pod_name, log_content in logs_dict.items():
            entries = []
            
            if not log_content or log_content.startswith('[ERROR]'):
                print(f"âš ï¸ Pod {pod_name} æ—¥å¿—ä¸ºç©ºæˆ–æœ‰é”™è¯¯")
                parsed_logs[pod_name] = entries
                continue
            
            lines = log_content.strip().split('\n')
            for line in lines:
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    entry = self.parse_log_entry(line, pod_name)
                    if entry:
                        entries.append(entry)
            
            parsed_logs[pod_name] = entries
            print(f"ğŸ“Š Pod {pod_name}: è§£æåˆ° {len(entries)} æ¡è®¿é—®æ—¥å¿—")
        
        return parsed_logs
    
    def analyze_distribution(self, parsed_logs: Dict[str, List[LogEntry]], 
                           service_name: str) -> Dict[str, any]:
        """
        åˆ†æè¯·æ±‚åˆ†å¸ƒæƒ…å†µ
        
        Args:
            parsed_logs: è§£æåçš„æ—¥å¿—æ•°æ®
            service_name: æœåŠ¡åç§°
            
        Returns:
            åˆ†å¸ƒåˆ†æç»“æœ
        """
        total_requests = 0
        pod_distribution = Counter()
        version_distribution = Counter()
        status_code_distribution = Counter()
        response_times = []
        
        # ç»Ÿè®¡å„ä¸ªæŒ‡æ ‡
        for pod_name, entries in parsed_logs.items():
            request_count = len(entries)
            total_requests += request_count
            pod_distribution[pod_name] = request_count
            
            # ä» pod åç§°æå–ç‰ˆæœ¬ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šreviews-v2-xxx -> v2ï¼‰
            version = self._extract_version_from_pod(pod_name)
            if version:
                version_distribution[version] += request_count
            
            # ç»Ÿè®¡çŠ¶æ€ç å’Œå“åº”æ—¶é—´
            for entry in entries:
                status_code_distribution[entry.status_code] += 1
                if entry.request_time > 0:
                    response_times.append(entry.request_time)
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        pod_percentages = {}
        version_percentages = {}
        
        if total_requests > 0:
            for pod, count in pod_distribution.items():
                pod_percentages[pod] = count / total_requests
            
            for version, count in version_distribution.items():
                version_percentages[version] = count / total_requests
        
        # è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡
        response_time_stats = {}
        if response_times:
            response_time_stats = {
                'avg': statistics.mean(response_times),
                'median': statistics.median(response_times),
                'min': min(response_times),
                'max': max(response_times),
                'p95': self._percentile(response_times, 95),
                'p99': self._percentile(response_times, 99)
            }
        
        return {
            'service_name': service_name,
            'total_requests': total_requests,
            'pod_distribution': dict(pod_distribution),
            'pod_percentages': pod_percentages,
            'version_distribution': dict(version_distribution),
            'version_percentages': version_percentages,
            'status_code_distribution': dict(status_code_distribution),
            'response_time_stats': response_time_stats,
            'success_rate': self._calculate_success_rate(status_code_distribution),
            'error_rate': self._calculate_error_rate(status_code_distribution)
        }
    
    def verify_weight_distribution(self, distribution_result: Dict[str, any], 
                                 expected_weights: Dict[str, float],
                                 margin_of_error: float = 0.1) -> Dict[str, any]:
        """
        éªŒè¯æƒé‡åˆ†å¸ƒæ˜¯å¦ç¬¦åˆé¢„æœŸ
        
        Args:
            distribution_result: analyze_distribution çš„ç»“æœ
            expected_weights: æœŸæœ›çš„æƒé‡åˆ†å¸ƒ {version: weight}
            margin_of_error: å®¹é”™ç‡
            
        Returns:
            éªŒè¯ç»“æœ
        """
        version_percentages = distribution_result.get('version_percentages', {})
        total_requests = distribution_result.get('total_requests', 0)
        
        verification_results = {}
        overall_passed = True
        
        for version, expected_weight in expected_weights.items():
            actual_percentage = version_percentages.get(version, 0.0)
            deviation = abs(actual_percentage - expected_weight)
            passed = deviation <= margin_of_error
            
            if not passed:
                overall_passed = False
            
            verification_results[version] = {
                'expected_weight': expected_weight,
                'actual_percentage': actual_percentage,
                'deviation': deviation,
                'passed': passed,
                'request_count': distribution_result['version_distribution'].get(version, 0)
            }
        
        return {
            'overall_passed': overall_passed,
            'total_requests': total_requests,
            'margin_of_error': margin_of_error,
            'version_results': verification_results,
            'summary': self._generate_weight_summary(verification_results, overall_passed)
        }
    
    def _extract_version_from_pod(self, pod_name: str) -> Optional[str]:
        """ä» pod åç§°æå–ç‰ˆæœ¬ä¿¡æ¯"""
        # åŒ¹é…æ¨¡å¼ï¼šservicename-v1-xxx, servicename-v2-xxx
        match = re.search(r'-v(\d+)-', pod_name)
        if match:
            return f"v{match.group(1)}"
        
        # åŒ¹é…æ¨¡å¼ï¼šservicename-v1, servicename-v2  
        match = re.search(r'-v(\d+)$', pod_name)
        if match:
            return f"v{match.group(1)}"
        
        return None
    
    def _percentile(self, data: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0.0
        
        sorted_data = sorted(data)
        index = (percentile / 100.0) * (len(sorted_data) - 1)
        
        if index.is_integer():
            return sorted_data[int(index)]
        else:
            lower = sorted_data[int(index)]
            upper = sorted_data[int(index) + 1]
            return lower + (upper - lower) * (index - int(index))
    
    def _calculate_success_rate(self, status_distribution: Counter) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        total = sum(status_distribution.values())
        if total == 0:
            return 0.0
        
        success_count = sum(count for status, count in status_distribution.items() 
                          if 200 <= status < 400)
        return success_count / total
    
    def _calculate_error_rate(self, status_distribution: Counter) -> float:
        """è®¡ç®—é”™è¯¯ç‡"""
        return 1.0 - self._calculate_success_rate(status_distribution)
    
    def _generate_weight_summary(self, version_results: Dict[str, Dict], 
                                overall_passed: bool) -> str:
        """ç”Ÿæˆæƒé‡éªŒè¯æ‘˜è¦"""
        # æ„å»ºè¯¦ç»†çš„åˆ†å¸ƒä¿¡æ¯
        distribution_details = []
        for version, result in version_results.items():
            request_count = result['request_count']
            actual_percentage = result['actual_percentage']
            expected_weight = result['expected_weight']
            status = "âœ…" if result['passed'] else "âŒ"
            
            distribution_details.append(
                f"{status} {version}: {request_count}ä¸ªè¯·æ±‚ "
                f"({actual_percentage:.1%}, æœŸæœ›{expected_weight:.1%})"
            )
        
        distribution_summary = " | ".join(distribution_details)
        
        if overall_passed:
            return f"âœ… æƒé‡åˆ†å¸ƒéªŒè¯é€šè¿‡ - {distribution_summary}"
        else:
            failed_versions = [v for v, r in version_results.items() if not r['passed']]
            return f"âŒ æƒé‡åˆ†å¸ƒéªŒè¯å¤±è´¥ - {distribution_summary} (åå·®è¶…å‡ºå®¹é”™èŒƒå›´: {', '.join(failed_versions)})"

# å·¥å…·å‡½æ•°
def parse_logs_from_files(log_files: List[str], parser: Optional[EnvoyLogParser] = None) -> Dict[str, List[LogEntry]]:
    """
    ä»æ–‡ä»¶ä¸­è§£ææ—¥å¿—
    
    Args:
        log_files: æ—¥å¿—æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        parser: æ—¥å¿—è§£æå™¨å®ä¾‹
        
    Returns:
        è§£æç»“æœ
    """
    if parser is None:
        parser = EnvoyLogParser()
    
    logs_dict = {}
    
    for file_path in log_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ä»æ–‡ä»¶åæå– pod åç§°
            import os
            filename = os.path.basename(file_path)
            pod_name = filename.replace('.log', '').split('_')[-1]  # å‡è®¾æ ¼å¼ä¸º case_001_reviews_v2_pod-name.log
            
            logs_dict[pod_name] = content
            
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ—¥å¿—æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
    
    return parser.parse_logs_batch(logs_dict) 