#!/usr/bin/env python3
"""
ä¸»éªŒè¯ç¨‹åº

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•´ä¸ªéªŒè¯æ¨¡å—è¿›è¡Œï¼š
1. æ—¥å¿—è§£æ
2. è¡Œä¸ºæ¨¡å‹ç”Ÿæˆ
3. ç»“æœå¯¹æ¯”
4. æŠ¥å‘Šç”Ÿæˆ
"""

import sys
import os
sys.path.append(os.path.abspath('.'))
sys.path.append(os.path.abspath('..'))

import json
import argparse
from datetime import datetime
from typing import Dict, List

from .log_parser import EnvoyLogParser, parse_logs_from_files
from .behavior_model import BehaviorModel, parse_test_matrix
from .result_comparator import ResultComparator, compare_batch_results
from .report_generator import ReportGenerator

def extract_http_results_from_traffic_driver(case_id: str) -> Dict:
    """
    ä»traffic_driverçš„æ‰§è¡Œç»“æœä¸­æå–HTTPæµ‹è¯•ç»“æœ
    
    Args:
        case_id: æµ‹è¯•ç”¨ä¾‹ID
        
    Returns:
        HTTPæµ‹è¯•ç»“æœå­—å…¸ï¼ŒåŒ…å«çŠ¶æ€ç ã€å“åº”æ—¶é—´ç­‰ä¿¡æ¯
    """
    import os
    import json
    import glob
    
    # æŸ¥æ‰¾HTTPç»“æœæ–‡ä»¶
    http_results_dir = "../results/http_results"
    if not os.path.exists(http_results_dir):
        print(f"âš ï¸  HTTPç»“æœç›®å½•ä¸å­˜åœ¨: {http_results_dir}")
        return None
    
    # æŸ¥æ‰¾åŒ¹é…çš„HTTPç»“æœæ–‡ä»¶
    pattern = os.path.join(http_results_dir, f"{case_id}_http_result_*.json")
    files = glob.glob(pattern)
    
    if not files:
        print(f"âš ï¸  æœªæ‰¾åˆ°ç”¨ä¾‹ {case_id} çš„HTTPç»“æœæ–‡ä»¶")
        return None
    
    # è·å–æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(files, key=os.path.getctime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            http_result = data.get('http_result', {})
            print(f"ğŸ“Š ä» {latest_file} åŠ è½½HTTPç»“æœ")
            return http_result
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"âŒ è¯»å–HTTPç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        return None

def load_logs_from_directory(log_dir: str) -> Dict[str, Dict[str, List]]:
    """
    ä»ç›®å½•ä¸­åŠ è½½æ—¥å¿—æ–‡ä»¶
    
    Args:
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
        
    Returns:
        {case_id: {pod_name: log_content}} æ ¼å¼çš„æ—¥å¿—æ•°æ®
    """
    logs_by_case = {}
    parser = EnvoyLogParser()
    
    if not os.path.exists(log_dir):
        print(f"âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_dir}")
        return logs_by_case
    
    print(f"ğŸ“ æ‰«ææ—¥å¿—ç›®å½•: {log_dir}")
    
    # æ‰«ææ—¥å¿—æ–‡ä»¶
    log_files = []
    for filename in os.listdir(log_dir):
        if filename.endswith('.log'):
            log_files.append(os.path.join(log_dir, filename))
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
    
    # æŒ‰ç”¨ä¾‹ ID åˆ†ç»„æ—¥å¿—æ–‡ä»¶
    for log_file in log_files:
        filename = os.path.basename(log_file)
        
        # è§£ææ–‡ä»¶åï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
        # - case_001_reviews_v2_pod-name.log (sidecar)
        # - case_001_gateway_istio-ingressgateway-pod.log (gateway)
        # - case_001_test503_reviews_pod-name.log (test)
        parts = filename.replace('.log', '').split('_')
        if len(parts) >= 2:
            case_id = f"{parts[0]}_{parts[1]}"  # case_001
            
            if case_id not in logs_by_case:
                logs_by_case[case_id] = {}
            
            # è¯»å–æ—¥å¿—å†…å®¹
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ ¹æ®ä¸åŒæ–‡ä»¶ç±»å‹æå–æ ‡è¯†ç¬¦
                if len(parts) >= 3 and parts[2] == 'gateway':
                    # Gatewayæ—¥å¿—ï¼šcase_001_gateway_istio-ingressgateway-pod.log
                    pod_name = f"gateway_{parts[3]}" if len(parts) > 3 else "gateway_unknown"
                    log_type = "gateway"
                elif len(parts) >= 3 and parts[2] == 'test503':
                    # Testæ—¥å¿—ï¼šcase_001_test503_reviews_pod-name.log
                    pod_name = f"test503_{'_'.join(parts[3:])}"
                    log_type = "test"
                else:
                    # æ™®é€šsidecaræ—¥å¿—ï¼šcase_001_reviews_v2_pod-name.log
                    pod_name = '_'.join(parts[2:])
                    log_type = "sidecar"
                
                logs_by_case[case_id][pod_name] = content
                
                print(f"  âœ… åŠ è½½ {case_id} - {pod_name} ({log_type})")
                
            except Exception as e:
                print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {log_file}: {e}")
    
    # è§£ææ—¥å¿—å†…å®¹
    parsed_logs_by_case = {}
    for case_id, logs_dict in logs_by_case.items():
        parsed_logs = parser.parse_logs_batch(logs_dict)
        parsed_logs_by_case[case_id] = parsed_logs
        
        total_entries = sum(len(entries) for entries in parsed_logs.values())
        print(f"ğŸ“Š {case_id}: è§£æåˆ° {total_entries} æ¡æ—¥å¿—æ¡ç›®")
    
    return parsed_logs_by_case

def run_verification(matrix_file: str, log_dir: str, output_dir: str = "results/verification", istio_config_file: str = None):
    """
    è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹
    
    Args:
        matrix_file: æµ‹è¯•çŸ©é˜µæ–‡ä»¶è·¯å¾„
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„  
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        istio_config_file: Istioé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # è®¾ç½®è¾“å‡ºç¼–ç ï¼ˆWindows å…¼å®¹ï¼‰
    import sys
    import io
    if sys.platform == 'win32' and hasattr(sys.stdout, 'buffer'):
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        except:
            pass
    
    print("[INFO] å¼€å§‹ Istio åŠ¨æ€æµ‹è¯•éªŒè¯æµç¨‹")
    print("=" * 60)
    
    # æ”¶é›†éªŒè¯è¿‡ç¨‹ä¿¡æ¯
    verification_process = {
        "start_time": datetime.now().isoformat(),
        "matrix_file": matrix_file,
        "log_dir": log_dir,
        "istio_config_file": istio_config_file,
        "steps": []
    }
    
    # 1. è§£ææµ‹è¯•çŸ©é˜µï¼Œç”ŸæˆæœŸæœ›è¡Œä¸º
    print("\nğŸ“‹ ç¬¬ä¸€æ­¥ï¼šè§£ææµ‹è¯•çŸ©é˜µ")
    if istio_config_file:
        print(f"ğŸ”§ ä½¿ç”¨Istioé…ç½®æ–‡ä»¶: {istio_config_file}")
    
    step1_start = datetime.now()
    expected_behaviors = parse_test_matrix(matrix_file, istio_config_file)
    step1_end = datetime.now()
    
    # è®°å½•ç¬¬ä¸€æ­¥è¯¦æƒ…
    step1_info = {
        "step": 1,
        "name": "è§£ææµ‹è¯•çŸ©é˜µ",
        "start_time": step1_start.isoformat(),
        "end_time": step1_end.isoformat(),
        "duration_ms": (step1_end - step1_start).total_seconds() * 1000,
        "matrix_file": matrix_file,
        "istio_config_file": istio_config_file,
        "parsed_behaviors_count": len(expected_behaviors),
        "behaviors_summary": []
    }
    
    if not expected_behaviors:
        print("âŒ æœªèƒ½è§£æåˆ°ä»»ä½•æœŸæœ›è¡Œä¸ºï¼Œæ£€æŸ¥æµ‹è¯•çŸ©é˜µæ–‡ä»¶")
        step1_info["error"] = "æœªèƒ½è§£æåˆ°ä»»ä½•æœŸæœ›è¡Œä¸º"
        verification_process["steps"].append(step1_info)
        return
    
    print(f"âœ… æˆåŠŸè§£æ {len(expected_behaviors)} ä¸ªæœŸæœ›è¡Œä¸º")
    
    # è®°å½•æœŸæœ›è¡Œä¸ºè¯¦æƒ…
    for i, behavior in enumerate(expected_behaviors):
        behavior_summary = {
            "case_id": f"case_{i+1:03d}",
            "test_type": behavior.test_type.value,
            "policy_type": behavior.policy_type.value,
            "description": behavior.description,
            "expected_destination": behavior.expected_destination,
            "expected_distribution": behavior.expected_distribution,
            "expected_retry_attempts": behavior.expected_retry_attempts,
            "expected_per_try_timeout": behavior.expected_per_try_timeout,
            "expected_trip_threshold": behavior.expected_trip_threshold,
            "expected_trip_timeout": behavior.expected_trip_timeout,
            "expected_recovery_time": behavior.expected_recovery_time
        }
        step1_info["behaviors_summary"].append(behavior_summary)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        print(f"   ğŸ“ Case {i+1:03d}: {behavior.policy_type.value} - {behavior.description}")
        if behavior.expected_retry_attempts:
            print(f"      ğŸ”„ é‡è¯•: {behavior.expected_retry_attempts}æ¬¡, å•æ¬¡è¶…æ—¶: {behavior.expected_per_try_timeout}s")
        if behavior.expected_trip_threshold:
            print(f"      âš¡ ç†”æ–­: é˜ˆå€¼{behavior.expected_trip_threshold}, æ¢å¤æ—¶é—´: {behavior.expected_recovery_time}s")
    
    verification_process["steps"].append(step1_info)
    
    # 2. åŠ è½½å’Œè§£ææ—¥å¿—
    print("\nğŸ“„ ç¬¬äºŒæ­¥ï¼šåŠ è½½å’Œè§£ææ—¥å¿—")
    step2_start = datetime.now()
    parsed_logs_by_case = load_logs_from_directory(log_dir)
    step2_end = datetime.now()
    
    # è®°å½•ç¬¬äºŒæ­¥è¯¦æƒ…
    step2_info = {
        "step": 2,
        "name": "åŠ è½½å’Œè§£ææ—¥å¿—",
        "start_time": step2_start.isoformat(),
        "end_time": step2_end.isoformat(),
        "duration_ms": (step2_end - step2_start).total_seconds() * 1000,
        "log_dir": log_dir,
        "cases_with_logs_count": len(parsed_logs_by_case),
        "log_summary": []
    }
    
    if not parsed_logs_by_case:
        print("âŒ æœªèƒ½åŠ è½½åˆ°ä»»ä½•æ—¥å¿—æ•°æ®ï¼Œæ£€æŸ¥æ—¥å¿—ç›®å½•")
        step2_info["error"] = "æœªèƒ½åŠ è½½åˆ°ä»»ä½•æ—¥å¿—æ•°æ®"
        verification_process["steps"].append(step2_info)
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(parsed_logs_by_case)} ä¸ªç”¨ä¾‹çš„æ—¥å¿—")
    
    # è®°å½•æ—¥å¿—è§£æè¯¦æƒ…
    total_log_entries = 0
    for case_id, parsed_logs in parsed_logs_by_case.items():
        case_log_entries = sum(len(entries) for entries in parsed_logs.values())
        total_log_entries += case_log_entries
        
        pod_count = len(parsed_logs)
        success_entries = sum(len([e for e in entries if e.is_success]) for entries in parsed_logs.values())
        error_entries = sum(len([e for e in entries if e.is_error]) for entries in parsed_logs.values())
        
        log_case_summary = {
            "case_id": case_id,
            "total_entries": case_log_entries,
            "pod_count": pod_count,
            "success_entries": success_entries,
            "error_entries": error_entries,
            "success_rate": success_entries / case_log_entries if case_log_entries > 0 else 0,
            "pods": list(parsed_logs.keys())
        }
        step2_info["log_summary"].append(log_case_summary)
        
        success_rate = success_entries / case_log_entries if case_log_entries > 0 else 0
        print(f"   ğŸ“Š {case_id}: {case_log_entries}æ¡æ—¥å¿—, {pod_count}ä¸ªPod, æˆåŠŸç‡{success_rate:.1%}")
    
    step2_info["total_log_entries"] = total_log_entries
    verification_process["steps"].append(step2_info)
    
    # 3. æ‰§è¡Œå¯¹æ¯”éªŒè¯
    print("\n[STEP 3] ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œå¯¹æ¯”éªŒè¯")
    step3_start = datetime.now()
    comparator = ResultComparator()
    # ä¼ å…¥ http_results ç›®å½•ï¼Œå¯ç”¨å¤šç»´åº¦éªŒè¯ï¼ˆHTTP + æ—¥å¿—ï¼‰
    verification_results = compare_batch_results(
        expected_behaviors,
        parsed_logs_by_case,
        comparator,
        http_results_dir=os.path.join(os.path.dirname(log_dir), 'http_results')
    )
    
    step3_end = datetime.now()
    
    # è®°å½•ç¬¬ä¸‰æ­¥è¯¦æƒ…
    step3_info = {
        "step": 3,
        "name": "æ‰§è¡Œå¯¹æ¯”éªŒè¯",
        "start_time": step3_start.isoformat(),
        "end_time": step3_end.isoformat(),
        "duration_ms": (step3_end - step3_start).total_seconds() * 1000,
        "verification_results_count": len(verification_results) if verification_results else 0,
        "verification_summary": []
    }
    
    if not verification_results:
        print("âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        step3_info["error"] = "éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
        verification_process["steps"].append(step3_info)
        return
    
    print(f"âœ… å®Œæˆ {len(verification_results)} ä¸ªç”¨ä¾‹çš„éªŒè¯")
    
    # è®°å½•éªŒè¯ç»“æœè¯¦æƒ…
    passed_count = 0
    failed_count = 0
    warning_count = 0
    
    for result in verification_results:
        if result.overall_status.value == "passed":
            passed_count += 1
        elif result.overall_status.value == "failed":
            failed_count += 1
        elif result.overall_status.value == "warning":
            warning_count += 1
        
        # æ”¶é›†å„ç»´åº¦éªŒè¯ç»“æœ
        dimension_results = {}
        for verification in result.individual_results:
            dimension_results[verification.test_name] = {
                "status": verification.status.value,
                "message": verification.message,
                "expected_value": verification.expected_value,
                "actual_value": verification.actual_value,
                "deviation": verification.deviation,
                "details": verification.details
            }
        
        verification_case_summary = {
            "case_id": result.case_id,
            "test_description": result.test_description,
            "overall_status": result.overall_status.value,
            "dimension_results": dimension_results,
            "summary": result.summary,
            "metrics": result.metrics
        }
        step3_info["verification_summary"].append(verification_case_summary)
        
        # æ‰“å°éªŒè¯è¯¦æƒ…
        status_icon = {"passed": "âœ…", "failed": "âŒ", "warning": "âš ï¸"}.get(result.overall_status.value, "â“")
        print(f"   {status_icon} {result.case_id}: {result.overall_status.value.upper()}")
        
        # æ‰“å°å„ç»´åº¦ç»“æœ
        for verification in result.individual_results:
            dim_icon = {"passed": "âœ…", "failed": "âŒ", "warning": "âš ï¸", "skipped": "â­ï¸"}.get(verification.status.value, "â“")
            print(f"      {dim_icon} {verification.test_name}: {verification.message}")
    
    step3_info["passed_count"] = passed_count
    step3_info["failed_count"] = failed_count
    step3_info["warning_count"] = warning_count
    step3_info["total_count"] = len(verification_results)
    verification_process["steps"].append(step3_info)
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“Š ç¬¬å››æ­¥ï¼šç”ŸæˆéªŒè¯æŠ¥å‘Š")
    step4_start = datetime.now()
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æµ‹è¯•é…ç½®
    test_config = None
    try:
        with open(matrix_file, 'r', encoding='utf-8') as f:
            test_config = json.load(f)
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½æµ‹è¯•é…ç½®: {e}")
    
    # å®ŒæˆéªŒè¯è¿‡ç¨‹è®°å½•
    verification_process["end_time"] = datetime.now().isoformat()
    verification_process["total_duration_ms"] = (datetime.now() - datetime.fromisoformat(verification_process["start_time"])).total_seconds() * 1000
    
    # å°†éªŒè¯è¿‡ç¨‹ä¿¡æ¯æ·»åŠ åˆ°æµ‹è¯•é…ç½®ä¸­
    if test_config is None:
        test_config = {}
    test_config["verification_process"] = verification_process
    
    # ç”ŸæˆæŠ¥å‘Š
    report_generator = ReportGenerator(output_dir)
    report_files = report_generator.generate_comprehensive_report(
        verification_results, test_config, "istio_verification"
    )
    step4_end = datetime.now()
    
    # è®°å½•ç¬¬å››æ­¥è¯¦æƒ…
    step4_info = {
        "step": 4,
        "name": "ç”ŸæˆéªŒè¯æŠ¥å‘Š",
        "start_time": step4_start.isoformat(),
        "end_time": step4_end.isoformat(),
        "duration_ms": (step4_end - step4_start).total_seconds() * 1000,
        "output_dir": output_dir,
        "generated_files": list(report_files.values()) if report_files else []
    }
    verification_process["steps"].append(step4_info)
    
    # 5. æ˜¾ç¤ºéªŒè¯ç»“æœæ‘˜è¦
    print("\nğŸ“ˆ ç¬¬äº”æ­¥ï¼šéªŒè¯ç»“æœæ‘˜è¦")
    print("-" * 40)
    
    passed_count = sum(1 for r in verification_results if r.overall_status.value == 'passed')
    failed_count = sum(1 for r in verification_results if r.overall_status.value == 'failed')
    warning_count = sum(1 for r in verification_results if r.overall_status.value == 'warning')
    
    print(f"âœ… é€šè¿‡ç”¨ä¾‹: {passed_count}")
    print(f"âŒ å¤±è´¥ç”¨ä¾‹: {failed_count}")
    print(f"âš ï¸ è­¦å‘Šç”¨ä¾‹: {warning_count}")
    print(f"ğŸ“Š æ€»æˆåŠŸç‡: {passed_count / len(verification_results) * 100:.1f}%")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for result in verification_results:
        status_symbol = {
            'passed': 'âœ…',
            'failed': 'âŒ', 
            'warning': 'âš ï¸',
            'skipped': 'â­ï¸'
        }.get(result.overall_status.value, 'â“')
        
        print(f"  {status_symbol} {result.case_id}: {result.summary}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„éªŒè¯é¡¹
        failed_verifications = [v for v in result.individual_results 
                              if v.status.value == 'failed']
        if failed_verifications:
            for verification in failed_verifications:
                print(f"      âŒ {verification.test_name}: {verification.message}")
    
    print("\nğŸ‰ éªŒè¯æµç¨‹å®Œæˆï¼")
    print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶å·²ç”Ÿæˆåˆ°: {output_dir}")

def analyze_single_case(case_id: str, log_dir: str, matrix_file: str, istio_config_file: str = None):
    """
    åˆ†æå•ä¸ªæµ‹è¯•ç”¨ä¾‹
    
    Args:
        case_id: ç”¨ä¾‹ ID
        log_dir: æ—¥å¿—ç›®å½•
        matrix_file: æµ‹è¯•çŸ©é˜µæ–‡ä»¶
    """
    print(f"[ANALYZE] åˆ†æå•ä¸ªç”¨ä¾‹: {case_id}")
    print("=" * 40)
    
    # 1. åŠ è½½æœŸæœ›è¡Œä¸º
    expected_behaviors = parse_test_matrix(matrix_file, istio_config_file)
    target_behavior = None
    
    
    for i, behavior in enumerate(expected_behaviors):
        # æ ¹æ®ç´¢å¼•ç”Ÿæˆ case_id
        generated_case_id = f"case_{i+1:03d}"
        if case_id == generated_case_id:
            target_behavior = behavior
            break
    
    if not target_behavior:
        print(f"âŒ æœªæ‰¾åˆ°ç”¨ä¾‹ {case_id} çš„æœŸæœ›è¡Œä¸º")
        return
    
    # 2. åŠ è½½æ—¥å¿—
    parsed_logs_by_case = load_logs_from_directory(log_dir)
    
    if case_id not in parsed_logs_by_case:
        print(f"âŒ æœªæ‰¾åˆ°ç”¨ä¾‹ {case_id} çš„æ—¥å¿—æ•°æ®")
        print(f"å¯ç”¨ç”¨ä¾‹: {list(parsed_logs_by_case.keys())}")
        return
    
    parsed_logs = parsed_logs_by_case[case_id]
    
    # 3. æ‰§è¡ŒéªŒè¯ (å¤šç»´åº¦éªŒè¯)
    comparator = ResultComparator()
    
    # å°è¯•ä»traffic_driverç»“æœä¸­è·å–HTTPç»“æœ
    http_results = extract_http_results_from_traffic_driver(case_id)
    
    result = comparator.compare_single_result(case_id, target_behavior, parsed_logs, http_results)
    
    # 4. æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print(f"\nğŸ“Š ç”¨ä¾‹ {case_id} åˆ†æç»“æœ:")
    print(f"çŠ¶æ€: {result.overall_status.value}")
    print(f"æè¿°: {result.test_description}")
    print(f"æ‘˜è¦: {result.summary}")
    
    print(f"\nğŸ“ˆ æŒ‡æ ‡æ•°æ®:")
    for key, value in result.metrics.items():
        print(f"  {key}: {value}")
    
    print(f"\n[DETAIL] éªŒè¯è¯¦æƒ…:")
    for verification in result.individual_results:
        status_symbol = {
            'passed': 'âœ…',
            'failed': 'âŒ',
            'warning': 'âš ï¸',
            'skipped': 'â­ï¸'
        }.get(verification.status.value, 'â“')
        
        print(f"  {status_symbol} {verification.test_name}: {verification.message}")
        
        # å¯¹äºæµé‡åˆ†å¸ƒéªŒè¯ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¿¡æ¯
        if verification.test_name == "æµé‡åˆ†å¸ƒéªŒè¯" and verification.details:
            version_results = verification.details.get('version_results', {})
            if version_results:
                print(f"      ğŸ“Š è¯¦ç»†åˆ†å¸ƒ:")
                for version, result in version_results.items():
                    count = result['request_count']
                    actual = result['actual_percentage']
                    expected = result['expected_weight']
                    deviation = result['deviation']
                    status_icon = "âœ…" if result['passed'] else "âŒ"
                    print(f"        {status_icon} {version}: {count}ä¸ªè¯·æ±‚ ({actual:.1%}) vs æœŸæœ›({expected:.1%}) åå·®({deviation:.1%})")
        elif verification.details:
            # å…¶ä»–éªŒè¯ç±»å‹æ˜¾ç¤ºåŸæœ‰è¯¦æƒ…
            for detail_key, detail_value in verification.details.items():
                if detail_key not in ['version_results', 'summary']:  # é¿å…é‡å¤æ˜¾ç¤º
                    print(f"      {detail_key}: {detail_value}")

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    parser = argparse.ArgumentParser(description='Istio åŠ¨æ€æµ‹è¯•éªŒè¯å·¥å…·')
    
    parser.add_argument('--matrix', '-m', 
                       default='output_matrix.json',
                       help='æµ‹è¯•çŸ©é˜µæ–‡ä»¶è·¯å¾„')
    
    parser.add_argument('--logs', '-l',
                       default='results/envoy_logs',
                       help='æ—¥å¿—ç›®å½•è·¯å¾„')
    
    parser.add_argument('--output', '-o',
                       default='results/verification',
                       help='æŠ¥å‘Šè¾“å‡ºç›®å½•')
    
    parser.add_argument('--case', '-c',
                       help='åˆ†æå•ä¸ªç”¨ä¾‹ï¼ˆç”¨ä¾‹IDï¼‰')
    
    parser.add_argument('--demo', action='store_true',
                       help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼ï¼ˆä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼‰')
    
    parser.add_argument('--config', '-cfg',
                       help='Istioé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæå–é‡è¯•ã€ç†”æ–­ç­‰æ—¶é—´å‚æ•°ï¼‰')
    
    args = parser.parse_args()
    
    if args.demo:
        print("ğŸ§ª æ¼”ç¤ºæ¨¡å¼ï¼šåˆ›å»ºç¤ºä¾‹æ•°æ®å¹¶è¿è¡ŒéªŒè¯")
        create_demo_data()
        run_verification('demo_matrix.json', 'demo_logs', 'demo_results')
    elif args.case:
        analyze_single_case(args.case, args.logs, args.matrix, args.config)
    else:
        run_verification(args.matrix, args.logs, args.output, args.config)

def create_demo_data():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    print("ğŸ“ åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
    
    # åˆ›å»ºç¤ºä¾‹æµ‹è¯•çŸ©é˜µ
    demo_matrix = {
        "global_settings": {
            "ingress_url": "http://192.168.92.131:30476/productpage"
        },
        "test_cases": [
            {
                "case_id": "case_001",
                "description": "è·¯ç”±æµ‹è¯• - è¯·æ±‚è·¯ç”±åˆ° reviews-v2",
                "type": "single_request",
                "request_params": {
                    "host": "reviews",
                    "headers": {"user-agent": "jason"}
                },
                "expected_outcome": {
                    "destination": "v2",
                    "note": "éªŒè¯è·¯ç”±åˆ° v2 ç‰ˆæœ¬"
                }
            },
            {
                "case_id": "case_002", 
                "description": "æµé‡åˆ†å¸ƒæµ‹è¯• - 80% v1, 20% v3",
                "type": "load_test",
                "request_params": {
                    "host": "reviews"
                },
                "load_params": {
                    "num_requests": 50,
                    "concurrency": 1
                },
                "expected_outcome": {
                    "distribution": {
                        "v1": "0.80",
                        "v3": "0.20"
                    },
                    "margin_of_error": "0.05"
                }
            }
        ]
    }
    
    with open('demo_matrix.json', 'w', encoding='utf-8') as f:
        json.dump(demo_matrix, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºç¤ºä¾‹æ—¥å¿—ç›®å½•å’Œæ–‡ä»¶
    os.makedirs('demo_logs', exist_ok=True)
    
    # åˆ›å»º case_001 çš„æ—¥å¿—ï¼ˆè·¯ç”±åˆ° v2ï¼‰
    demo_log_v2 = '''[2024-01-15T10:30:15.123Z] "GET /reviews/2 HTTP/1.1" 200 - 0 157 45 12 "192.168.1.100" "jason" "abc123" "reviews" "10.244.1.15:9080"
[2024-01-15T10:30:16.456Z] "GET /reviews/2 HTTP/1.1" 200 - 0 161 52 15 "192.168.1.100" "jason" "def456" "reviews" "10.244.1.15:9080"'''
    
    with open('demo_logs/case_001_reviews-v2-abc123.log', 'w', encoding='utf-8') as f:
        f.write(demo_log_v2)
    
    # åˆ›å»º case_002 çš„æ—¥å¿—ï¼ˆæµé‡åˆ†å¸ƒï¼š40 ä¸ªè¯·æ±‚åˆ° v1, 10 ä¸ªè¯·æ±‚åˆ° v3ï¼‰
    demo_log_v1 = '\n'.join([
        f'[2024-01-15T10:35:{i:02d}.{i*100:03d}Z] "GET /reviews/1 HTTP/1.1" 200 - 0 {150+i} {40+i} {10+i//5} "192.168.1.100" "curl/7.68.0" "req{i:03d}" "reviews" "10.244.1.16:9080"'
        for i in range(40)
    ])
    
    demo_log_v3 = '\n'.join([
        f'[2024-01-15T10:35:{i:02d}.{i*100:03d}Z] "GET /reviews/3 HTTP/1.1" 200 - 0 {160+i} {45+i} {12+i//3} "192.168.1.100" "curl/7.68.0" "req{i+40:03d}" "reviews" "10.244.1.17:9080"'
        for i in range(10)
    ])
    
    with open('demo_logs/case_002_reviews-v1-def456.log', 'w', encoding='utf-8') as f:
        f.write(demo_log_v1)
        
    with open('demo_logs/case_002_reviews-v3-ghi789.log', 'w', encoding='utf-8') as f:
        f.write(demo_log_v3)
    
    print("âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆ")

if __name__ == "__main__":
    main() 